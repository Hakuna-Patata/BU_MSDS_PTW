"0",""
"0","## Outcome Variable already a numerical category so no need to convert."
"0","## Will scale the predictor variables to standardize distances."
"0",""
"0",""
"0","## Binary Classifier Data"
"0","# Scale Data"
"0","tc_df2 <- tc_df %>% "
"0","  dplyr::mutate( # scale/standardize predictor variables"
"0","    x = scale(x)"
"0","    , y = scale(y)"
"0","  )"
"0",""
"0","# Create Training/Testing data sets (80/20)"
"0","set.seed(777)"
"0","size <- floor(0.8 * nrow(tc_df2))"
"0","tc_df_indices <- sample(seq_len(nrow(tc_df2)), size=size)"
"0","tc_df_train <- tc_df2[tc_df_indices, c(""x"", ""y"", ""label"")]"
"0","tc_df_test <- tc_df2[-tc_df_indices, c(""x"", ""y"", ""label"")]"
"0","  "
"0","## Modeling"
"0","# square root of the number of rows in the training data set. If floor of that number is even then ceiling, else floor."
"0","k <- if (floor(sqrt(nrow(tc_df_train))) %/% 2 == 0) {"
"0","  ceiling(sqrt(nrow(tc_df_train)))"
"0","} else {"
"0","  floor(sqrt(nrow(tc_df_train)))"
"0","}"
"0",""
"0","bc_prediction <- knn(train = tc_df_train"
"0","                  , test = tc_df_test"
"0","                  , cl = tc_df_train$label"
"0","                  , k = 25"
"0","                  # , k = 299"
"0","                  )"
"0",""
"0","conf_matrix <- as.matrix(table(Actual=tc_df_test$label,Predicted=bc_prediction))"
"0",""
"0","conf_matrix"
"1","      Predicted
"
"1","Actual"
"1","   0"
"1","   1"
"1","   2"
"1","
     0"
"1","  79"
"1","   0"
"1","   0"
"1","
     1"
"1","   0"
"1"," 133"
"1","   0"
"1","
     2"
"1","   0"
"1","   0"
"1"," 102"
"1","
"
"0","model_accuracy <- round(100 * sum(conf_matrix[c(1,5,9)]) / sum(conf_matrix), 1)"
"0","mis_class <- 100-model_accuracy"
"0","sensitivity <- round(100 * sum(conf_matrix[c(4)]) / sum(conf_matrix[c(2,4)]), 1)"
"0","specificity <- round(100 * sum(conf_matrix[c(1)]) / sum(conf_matrix[c(1,3)]), 1)"
"0",""
"0",""
"0","tc_df_test$predicted <- bc_prediction"
"0","tc_df_test$correct_label <- factor(ifelse(tc_df_test$label == tc_df_test$predicted, ""Y"", ""N""), levels = c(""Y"",""N""))"
"0","tc_df_test$correct <- fct_rev(factor(ifelse( tc_df_test$label == bc_prediction"
"0","                              , paste0(""Y: "", tc_df_test$label)"
"0","                              , paste0(""N p:"",tc_df_test$predicted, "", a:"",tc_df_test$label) "
"0","                              )))"
"0",""
"0","matrix1 <- confusionMatrix(as.factor(tc_df_test$predicted), as.factor(tc_df_test$label))"
"0",""
"0","model_accuracy <- paste0(""Model Accuracy: "", as.character(round(100 * matrix1$overall[""Accuracy""]), 2), ""%"")"
"0",""
"0","model_cat_info <- matrix1$byClass[,c(""Balanced Accuracy"", ""Sensitivity"", ""Specificity"")]"
"0",""
"0","print(model_cat_info)"
"1","        "
"1"," Balanced Accuracy"
"1"," Sensitivity"
"1"," Specificity"
"1","
Class: 0"
"1","                 1"
"1","           1"
"1","           1"
"1","
Class: 1"
"1","                 1"
"1","           1"
"1","           1"
"1","
Class: 2"
"1","                 1"
"1","           1"
"1","           1"
"1","
"
"0","ggplot(data = tc_df_test, mapping = aes(x=x, y=y)) + "
"0","  geom_point(mapping = aes(fill = correct, color = correct_label, pch = 21), size = 4, pch=21) +"
"0","  labs(fill=""Prediction Correct?"", title = ""Prediction vs. Actual"", subtitle = model_accuracy) + "
"0","  theme("
"0","    plot.title = element_text(face = ""bold"", size = 17)"
"0","  ) + "
"0","  scale_color_manual(values = c(""black"", ""red"")) + "
"0","  scale_fill_manual(values = c(""#1ba30f"",""#262aff"",""#fc38d8"",""#ccffce"",""#abb3ff"",""#ffbff3"")) + "
"0","  guides(color= FALSE)"
